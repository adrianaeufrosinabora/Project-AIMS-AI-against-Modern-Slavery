{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Deeplearning",
      "language": "python",
      "name": "deeplearning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Data Extraction - UK registry.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPOsaoCUblMu",
        "outputId": "28929fa5-7aa1-4efb-dcc7-30e3fa518934"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install requests\n",
        "!pip install pdfplumber\n",
        "!pip install jsonpickle\n",
        "!pip install boilerpy3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.5.28.tar.gz (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20200517\n",
            "  Downloading pdfminer.six-20200517-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfplumber) (7.1.2)\n",
            "Collecting Wand\n",
            "  Downloading Wand-0.6.7-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (3.0.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (2.4.0)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 42.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pdfplumber\n",
            "  Building wheel for pdfplumber (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfplumber: filename=pdfplumber-0.5.28-py3-none-any.whl size=32240 sha256=f5d0b3eb59ca542ec95864cb1400f55c3c6962d7bccfd9a2af8939905dee0e85\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/b1/a0/c0a77b756d580f53b3806ae0e0b3ec945a8d05fca1d6e10cc1\n",
            "Successfully built pdfplumber\n",
            "Installing collected packages: pycryptodome, Wand, pdfminer.six, pdfplumber\n",
            "Successfully installed Wand-0.6.7 pdfminer.six-20200517 pdfplumber-0.5.28 pycryptodome-3.11.0\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle) (3.6.0)\n",
            "Installing collected packages: jsonpickle\n",
            "Successfully installed jsonpickle-2.0.0\n",
            "Collecting boilerpy3\n",
            "  Downloading boilerpy3-1.0.5-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: boilerpy3\n",
            "Successfully installed boilerpy3-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGy4ZespblMy"
      },
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrS_qBLublMy"
      },
      "source": [
        "## Data download \n",
        "\n",
        "We fetch the data from the Modern Slavery Statement Registry page. For each of those statements, we use the 'StatementURL' column to fetch the original notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBVVsChvbvH4"
      },
      "source": [
        "base_statement_urls = [\"https://downloads.modern-slavery-statement-registry.service.gov.uk/publicdownloads/StatementSummaries2020.csv\",\n",
        "                       \"https://downloads.modern-slavery-statement-registry.service.gov.uk/publicdownloads/StatementSummaries2021.csv\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0iPa0Qgb19l"
      },
      "source": [
        "# Import requests\n",
        "import requests\n",
        "import bs4"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0_EuUvVdfwL"
      },
      "source": [
        "all_statements = [pd.read_csv(statement) for statement in base_statement_urls]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wWTo1FcdtDi"
      },
      "source": [
        "all_statements_df = pd.concat(all_statements)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "7KozbKn7fOSL",
        "outputId": "f07f6f5b-27a6-48b9-b8bb-29ff622dcbfd"
      },
      "source": [
        "all_statements_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StatementYear</th>\n",
              "      <th>OrganisationName</th>\n",
              "      <th>Address</th>\n",
              "      <th>SectorType</th>\n",
              "      <th>CompanyNumber</th>\n",
              "      <th>LastUpdated</th>\n",
              "      <th>GroupSubmission</th>\n",
              "      <th>ParentName</th>\n",
              "      <th>StatementURL</th>\n",
              "      <th>EmailAddressNoURL</th>\n",
              "      <th>StatementSummaryURL</th>\n",
              "      <th>StatementStartDate</th>\n",
              "      <th>StatementEndDate</th>\n",
              "      <th>ApprovingPerson</th>\n",
              "      <th>DateApproved</th>\n",
              "      <th>StatementIncludesOrgStructure</th>\n",
              "      <th>NoOrgStructureReason</th>\n",
              "      <th>StatementIncludesPolicies</th>\n",
              "      <th>NoPoliciesReason</th>\n",
              "      <th>StatementIncludesRisksAssessment</th>\n",
              "      <th>NoRiskAssessmentReason</th>\n",
              "      <th>StatementIncludesDueDiligence</th>\n",
              "      <th>NoDueDiligenceReason</th>\n",
              "      <th>StatementIncludesTraining</th>\n",
              "      <th>NoTrainingReason</th>\n",
              "      <th>StatementIncludesGoals</th>\n",
              "      <th>NoGoalsReason</th>\n",
              "      <th>OrganisationSectors</th>\n",
              "      <th>OtherOrganisationSector</th>\n",
              "      <th>Turnover</th>\n",
              "      <th>YearsProducingStatements</th>\n",
              "      <th>Policies</th>\n",
              "      <th>OtherPolicies</th>\n",
              "      <th>NoPolicies</th>\n",
              "      <th>Training</th>\n",
              "      <th>OtherTraining</th>\n",
              "      <th>NoTraining</th>\n",
              "      <th>WorkingConditionsEngagement</th>\n",
              "      <th>NoEngagement</th>\n",
              "      <th>SocialAudits</th>\n",
              "      <th>NoSocialAudits</th>\n",
              "      <th>GrievanceMechanisms</th>\n",
              "      <th>NoGrievanceMechanisms</th>\n",
              "      <th>OtherMonitoring</th>\n",
              "      <th>NoRisks</th>\n",
              "      <th>Risk1</th>\n",
              "      <th>Risk1Area</th>\n",
              "      <th>Risk1SupplyChainTier</th>\n",
              "      <th>Risk1GroupAffected</th>\n",
              "      <th>Risk1OtherGroupAffected</th>\n",
              "      <th>Risk1Location</th>\n",
              "      <th>Risk1Mitigation</th>\n",
              "      <th>Risk2</th>\n",
              "      <th>Risk2Area</th>\n",
              "      <th>Risk2SupplyChainTier</th>\n",
              "      <th>Risk2GroupAffected</th>\n",
              "      <th>Risk2OtherGroupAffected</th>\n",
              "      <th>Risk2Location</th>\n",
              "      <th>Risk2Mitigation</th>\n",
              "      <th>Risk3</th>\n",
              "      <th>Risk3Area</th>\n",
              "      <th>Risk3SupplyChainTier</th>\n",
              "      <th>Risk3GroupAffected</th>\n",
              "      <th>Risk3OtherGroupAffected</th>\n",
              "      <th>Risk3Location</th>\n",
              "      <th>Risk3Mitigation</th>\n",
              "      <th>ILOIndicatorsInStatement</th>\n",
              "      <th>NoILOIndicatorsInStatement</th>\n",
              "      <th>ILOIndicatorsActions</th>\n",
              "      <th>ILOIndicatorsNoActions</th>\n",
              "      <th>DemonstrateProgress</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020</td>\n",
              "      <td>Tullow (EA) Holdings Limited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14/05/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>TULLOW OIL PLC</td>\n",
              "      <td>https://www.tullowoil.com/application/files/71...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://modern-slavery-statement-registry.serv...</td>\n",
              "      <td>01/01/2020</td>\n",
              "      <td>31/12/2020</td>\n",
              "      <td>Dorothy Thompson (Chair)</td>\n",
              "      <td>21/04/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mining, metals, chemicals and resources (inclu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>£100 million to £500 million</td>\n",
              "      <td>1 to 5 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020</td>\n",
              "      <td>Tullow Ghana Limited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14/05/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>TULLOW OIL PLC</td>\n",
              "      <td>https://www.tullowoil.com/application/files/71...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://modern-slavery-statement-registry.serv...</td>\n",
              "      <td>01/01/2020</td>\n",
              "      <td>31/12/2020</td>\n",
              "      <td>Dorothy Thompson (Chair)</td>\n",
              "      <td>21/04/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mining, metals, chemicals and resources (inclu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>£100 million to £500 million</td>\n",
              "      <td>1 to 5 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020</td>\n",
              "      <td>Tullow Namibia Limited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14/05/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>TULLOW OIL PLC</td>\n",
              "      <td>https://www.tullowoil.com/application/files/71...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://modern-slavery-statement-registry.serv...</td>\n",
              "      <td>01/01/2020</td>\n",
              "      <td>31/12/2020</td>\n",
              "      <td>Dorothy Thompson (Chair)</td>\n",
              "      <td>21/04/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mining, metals, chemicals and resources (inclu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>£100 million to £500 million</td>\n",
              "      <td>1 to 5 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>Tullow Uganda Limited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14/05/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>TULLOW OIL PLC</td>\n",
              "      <td>https://www.tullowoil.com/application/files/71...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://modern-slavery-statement-registry.serv...</td>\n",
              "      <td>01/01/2020</td>\n",
              "      <td>31/12/2020</td>\n",
              "      <td>Dorothy Thompson (Chair)</td>\n",
              "      <td>21/04/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mining, metals, chemicals and resources (inclu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>£100 million to £500 million</td>\n",
              "      <td>1 to 5 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>Tullow Uganda Operations Pty Limited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14/05/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>TULLOW OIL PLC</td>\n",
              "      <td>https://www.tullowoil.com/application/files/71...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://modern-slavery-statement-registry.serv...</td>\n",
              "      <td>01/01/2020</td>\n",
              "      <td>31/12/2020</td>\n",
              "      <td>Dorothy Thompson (Chair)</td>\n",
              "      <td>21/04/2021</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mining, metals, chemicals and resources (inclu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>£100 million to £500 million</td>\n",
              "      <td>1 to 5 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   StatementYear  ... DemonstrateProgress\n",
              "0           2020  ...                 NaN\n",
              "1           2020  ...                 NaN\n",
              "2           2020  ...                 NaN\n",
              "3           2020  ...                 NaN\n",
              "4           2020  ...                 NaN\n",
              "\n",
              "[5 rows x 71 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntny9wb6blM0",
        "outputId": "87f707ee-9c64-48e8-e784-d417c874e0bd"
      },
      "source": [
        "df_company = all_statements_df\n",
        "df_company['StatementURL'].head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    https://www.tullowoil.com/application/files/71...\n",
              "1    https://www.tullowoil.com/application/files/71...\n",
              "2    https://www.tullowoil.com/application/files/71...\n",
              "3    https://www.tullowoil.com/application/files/71...\n",
              "4    https://www.tullowoil.com/application/files/71...\n",
              "Name: StatementURL, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vQeDXMHblM1"
      },
      "source": [
        "You can iterrate each row in the dataframe and download the corresponding data from the provided url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyVfn4U9blM1"
      },
      "source": [
        "import requests\n",
        "import re\n",
        "def download_file(url, local_file_location):\n",
        "    if not os.path.isfile(local_file_location):\n",
        "      r = requests.get(url, allow_redirects=True)\n",
        "      with open(local_file_location, 'wb') as f:\n",
        "            f.write(r.content)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUYAYIWp1djO"
      },
      "source": [
        "Store all the files in a temporary directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FzXvKdSblM2"
      },
      "source": [
        "LOCAL_FILE_FOLDER = 'data/'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt6MXyGEglcl"
      },
      "source": [
        "if not os.path.exists(LOCAL_FILE_FOLDER):\n",
        "  os.mkdir(LOCAL_FILE_FOLDER)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6A-W_2jFNLF"
      },
      "source": [
        "working_df = df_company"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apxcd_aizev7",
        "outputId": "c08fcdbb-5e73-4c84-bdb6-2e06d2abee93"
      },
      "source": [
        "working_df.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10525, 71)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VGT_iWT0blM2"
      },
      "source": [
        "%%time\n",
        "i = 0\n",
        "for _, row in working_df.iterrows():\n",
        "    url = row['StatementURL']\n",
        "    try:\n",
        "      # use the last part of the url as the local file name\n",
        "      file_path = url.split('/')[-1]\n",
        "      file_name = ''.join([LOCAL_FILE_FOLDER, file_path])\n",
        "      if i%20==0:\n",
        "        print(f\"Row {i}\")\n",
        "      if file_path:\n",
        "        download_file(url, file_name)\n",
        "      else:\n",
        "        print(f\"Empty url file extension: {url} at {i}, attempting to download as webpage\")\n",
        "        if(len(url.split(\"/\"))>4):\n",
        "          print(\"Attempting download of statement as HTML\")\n",
        "          filename = re.sub(\"/$\",\".html\",file_name)\n",
        "          download_file(url, filename)\n",
        "        else:\n",
        "          print(\"Skipping download, seems to be a home page.\")\n",
        "        \n",
        "    except:\n",
        "      print(f\"Impossible to download statement at row {i}, statement url {url}\")\n",
        "    i+=1\n",
        "    #print('downloaded', file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NHanf4qblM3"
      },
      "source": [
        "## Extract data from PDF\n",
        "\n",
        "The following code provides an example of extracting data from PDF files using a Python library called pdfplumber. However, you can choose any library as you prefer. \n",
        "\n",
        "You would need to do your own research if you wish to extract textual data from image file format such as png or jpg. However, the basic idea is to OCR the image file and then extract the text from the OCRed file.\n",
        "\n",
        "Note: there are scanned PDF files that should be treated as image files. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iQ_ZwJtblM4"
      },
      "source": [
        "## Extract data from HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK-kA7aJRkjO"
      },
      "source": [
        "The HTML is parsed using BS4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVxKxiVblM4"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import jsonpickle\n",
        "import pathlib\n",
        "import urllib.parse\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "from boilerpy3 import extractors\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "def accepted_tags(element):\n",
        "    TAGS = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6',\n",
        "            'section', 'a', 'a href', 'href', 'ul']\n",
        "    \n",
        "    if element.name in TAGS:\n",
        "        return True\n",
        "\n",
        "    elif element.parent.name in TAGS:\n",
        "        return True\n",
        "  \n",
        "    elif isinstance(element, Comment):\n",
        "        return False\n",
        "    \n",
        "    elif len(element)== 0:\n",
        "        return False\n",
        "    \n",
        "    return False\n",
        "\n",
        "def processing_extracted_text(input_slice):\n",
        "    list_sentences = []\n",
        "    list_tags = ['h2', 'h3', 'h4']\n",
        "    for text_element in input_slice:\n",
        "        if text_element.parent.name == 'p' and text_element.name == 'a':\n",
        "\n",
        "                if \"href\" in str(text_element) and 'slavery' in str(text_element).lower():\n",
        "                    if text_element.text+\" \"+text_element['href'] not in list_sentences:\n",
        "                        if text_element.text+\" \"+text_element['href'].strip():\n",
        "                            list_sentences.append(text_element.text+\" \"+text_element['href'])\n",
        "                else:\n",
        "                    continue\n",
        "        elif text_element.name == 'a':\n",
        "            if \"href\" in str(text_element) and 'slavery' in str(text_element).lower():\n",
        "                if text_element.text+\" \"+text_element['href'] not in list_sentences:\n",
        "                    if text_element.text+\" \"+text_element['href'].strip():\n",
        "                        list_sentences.append(text_element.text+\" \"+text_element['href'])\n",
        "        try:\n",
        "            if text_element.name == 'p' and text_element['class'] == 'copyright':\n",
        "                continue\n",
        "        except (AttributeError, KeyError):\n",
        "            pass\n",
        "\n",
        "        if text_element.parent.name == 'a' and text_element.name == 'p':\n",
        "            continue\n",
        "        if text_element.parent.name == 'a' and text_element.name == 'span':\n",
        "            continue\n",
        "        if text_element.parent.name == 'nav' and text_element.name in list_tags:\n",
        "            continue\n",
        "        if \"email\" in text_element.text.lower():\n",
        "            continue\n",
        "        if \"a href\" not in str(text_element) and text_element.name != 'a':\n",
        "    \n",
        "            splitted_text_element = text_element.text.split()\n",
        "            cleaned_element = ' '.join(splitted_text_element)\n",
        "            if cleaned_element not in list_sentences:\n",
        "                list_sentences.append(cleaned_element)\n",
        "    return list_sentences\n",
        "\n",
        "\n",
        "def filter_tags(body):\n",
        "    soup  = BeautifulSoup(body, \"html.parser\")\n",
        "    texts = soup.findAll(name = ['p','a', 'h1', 'h2', 'h3','h4','li', 'ul'])\n",
        "    accepted_headers = [ 'h1', 'h2']\n",
        "    extracted_data1 = list(filter(accepted_tags, texts))\n",
        "    extracted_data = list(dict.fromkeys(filter(None, extracted_data1)))\n",
        "    list_sentences = []\n",
        "\n",
        "    for i, text_element in enumerate(extracted_data):\n",
        "        \n",
        "        if text_element.name in accepted_headers and 'slavery' in str(text_element).lower():\n",
        "        \n",
        "            list_sentences = processing_extracted_text(extracted_data[i:])\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            list_sentences = processing_extracted_text(extracted_data)\n",
        "            \n",
        "            \n",
        "    return \"\\n\".join(list_sentences)\n",
        "\n",
        "\n",
        "def extract_filtered_data(html_file):\n",
        "    list_invalid_pages = [\"page was not found\", \"url was not found\", \"page can’t be found\",\"page isn't real\", \n",
        "    \"page is not real\", \"page not found\", \"error 404\", \"couldn't find the page\"]\n",
        "\n",
        "    with open (html_file, encoding='utf8',errors='replace') as f:\n",
        "        file_contents = f.read()\n",
        "\n",
        "        file_contents_without_metadata = filter_tags(file_contents).split(\"\\n\")\n",
        "        for sentence in file_contents_without_metadata:\n",
        "            if len(sentence.split())<=2:\n",
        "                file_contents_without_metadata.remove(sentence)\n",
        "\n",
        "        final_content = \"\\n\".join(file_contents_without_metadata)\n",
        "        \n",
        "        if any(element in final_content.lower() for element in list_invalid_pages):\n",
        "            return \"No Modern Slavery statement found\"\n",
        "                \n",
        "        elif len(final_content)==0:\n",
        "            return \"Nothing to return\"\n",
        "        \n",
        "        else:\n",
        "            return final_content "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGrUXlFRRoat"
      },
      "source": [
        "Now that all the files have been downloaded, perform text extraction according to the file extension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "O6GbcTN9blM6"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pdfplumber\n",
        "\n",
        "df_data = pd.DataFrame()\n",
        "for _, row in working_df.iterrows():\n",
        "    url = row['StatementURL']\n",
        "    if url and not pd.isna(url):\n",
        "      file_name = join(LOCAL_FILE_FOLDER, url.split('/')[-1])\n",
        "      if os.path.isfile(file_name):\n",
        "          all_text = ''\n",
        "          \n",
        "          if file_name.endswith('pdf'):\n",
        "              print(file_name)\n",
        "              try:\n",
        "                with pdfplumber.open(file_name) as pdf:\n",
        "                    for pdf_page in pdf.pages:\n",
        "                        single_page_text = pdf_page.extract_text()\n",
        "                        if single_page_text:\n",
        "                            all_text = all_text + '\\n' + single_page_text\n",
        "              except:\n",
        "                  print(f\"Impossible to parse PDF {file_name}\")\n",
        "                  all_text = \"ERROR PARSING PDF\"\n",
        "          elif file_name.endswith('html') :\n",
        "              all_text = extract_filtered_data(file_name)\n",
        "\n",
        "          row['extracted_text'] = all_text\n",
        "          df_data = df_data.append(row)\n",
        "    else:\n",
        "      row['extracted_text'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKvtA-ctblM6"
      },
      "source": [
        "df_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0tsWuAblM6"
      },
      "source": [
        "df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqA8EuisblM7"
      },
      "source": [
        "df_data.to_csv('data.csv', sep='|')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE6ZiJlzblM8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}